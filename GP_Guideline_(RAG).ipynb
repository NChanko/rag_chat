{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xEVsfWws5pqr"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n!pip3 install langchain\\n!pip3 install chromadb\\n!pip3 install langchain-openai\\n!pip3 install pytelegrambotapi\\n'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "!pip3 install langchain\n",
        "!pip3 install chromadb\n",
        "!pip3 install langchain-openai\n",
        "!pip3 install pytelegrambotapi\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXMVZefQswqI"
      },
      "source": [
        "https://www.google.com/search?q=langchain+vector+database+multiple+text+files&oq=langchain+vector+database+multiple+text+files&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIGCAEQLhhA0gEINTU2NWowajSoAgCwAgA&sourceid=chrome&ie=UTF-8#fpstate=ive&vld=cid:73da2684,vid:3yPBVii7Ct0,st:0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xk0w5fEb5nut"
      },
      "outputs": [],
      "source": [
        "openaikey = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter,RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_openai import ChatOpenAI\n",
        "import telebot\n",
        "import textwrap\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xP07WUSH8WUu"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n# Load the document, split it into chunks, embed each chunk and load it into the vector store.\\n#raw_documents = TextLoader(\\'/content/GP GUIDELINES_all.txt\\').load()\\nloader = DirectoryLoader(\\'./medical_books/\\', glob=\"./*.txt\", loader_cls=TextLoader)\\nraw_documents = loader.load()\\n\\n#splitting the text into\\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\\ndocuments = text_splitter.split_documents(raw_documents)\\n\\n#text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\\n#documents = text_splitter.split_documents(raw_documents)\\n\\n\\ndb = Chroma.from_documents(documents, OpenAIEmbeddings(openai_api_key=openaikey),persist_directory=\"./medical_db\")\\n'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "# Load the document, split it into chunks, embed each chunk and load it into the vector store.\n",
        "#raw_documents = TextLoader('/content/GP GUIDELINES_all.txt').load()\n",
        "loader = DirectoryLoader('./medical_books/', glob=\"./*.txt\", loader_cls=TextLoader)\n",
        "raw_documents = loader.load()\n",
        "\n",
        "#splitting the text into\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "documents = text_splitter.split_documents(raw_documents)\n",
        "\n",
        "#text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "#documents = text_splitter.split_documents(raw_documents)\n",
        "\n",
        "\n",
        "db = Chroma.from_documents(documents, OpenAIEmbeddings(openai_api_key=openaikey),persist_directory=\"./medical_db\")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#Updating with new documents. \n",
        "def process_documents(directory, db=None, is_new=False):\n",
        "    loader = DirectoryLoader(directory, glob=\"./*.txt\", loader_cls=TextLoader)\n",
        "    raw_documents = loader.load()\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    documents = text_splitter.split_documents(raw_documents)\n",
        "    \n",
        "    if not db:\n",
        "        # Initialize the database if it's not provided\n",
        "        db = Chroma.from_documents(documents, OpenAIEmbeddings(openai_api_key=openaikey), persist_directory=\"./medical_db\")\n",
        "    elif is_new:\n",
        "        # Update the database with new documents\n",
        "        # This step assumes `db` has a method like `add_documents` for adding new documents\n",
        "        db.add_documents(documents)\n",
        "        print(\"Added new documents to the database\")\n",
        "    \n",
        "    return db\n",
        "\n",
        "# Initial loading\n",
        "db = process_documents('./medical_books/')\n",
        "\n",
        "# Adding new documents\n",
        "process_documents('./new_books/', db=db, is_new=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLp8cWGiJh1Q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: medical_db/ (stored 0%)\n",
            "  adding: medical_db/chroma.sqlite3 (deflated 35%)\n",
            "  adding: medical_db/167f72a7-ce4b-4cc3-acb6-d3590bccca76/ (stored 0%)\n",
            "  adding: medical_db/167f72a7-ce4b-4cc3-acb6-d3590bccca76/data_level0.bin (deflated 17%)\n",
            "  adding: medical_db/167f72a7-ce4b-4cc3-acb6-d3590bccca76/length.bin (deflated 80%)\n",
            "  adding: medical_db/167f72a7-ce4b-4cc3-acb6-d3590bccca76/link_lists.bin (deflated 78%)\n",
            "  adding: medical_db/167f72a7-ce4b-4cc3-acb6-d3590bccca76/header.bin (deflated 56%)\n",
            "  adding: medical_db/167f72a7-ce4b-4cc3-acb6-d3590bccca76/index_metadata.pickle (deflated 77%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r medical_db.zip ./medical_db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUWFunmDCUFp",
        "outputId": "e9370161-3d23-4f55-f1dc-365ebbdc7a70"
      },
      "outputs": [],
      "source": [
        "bot_token = '5921411199:AAHWpDCZfEdZjTHH3BczaVKFPAzNc2XpbRk'  # Replace 'xx' with your actual bot token\n",
        "\n",
        "bot = telebot.TeleBot(bot_token)\n",
        "chat = ChatOpenAI(openai_api_key=openaikey)\n",
        "\n",
        "\n",
        "# Mock function to process the document and generate an answer\n",
        "def ask_question(question,context):\n",
        "    \"\"\"Asks a question to the LLM and gets the response.\"\"\"\n",
        "    # Prepare the messages with the question\n",
        "    messages = [\n",
        "        SystemMessage(content=f\"\"\"You are a helpful medical assistant.\n",
        "        You studied various medical books to give the best answer.\n",
        "        Based on what you have learned, give reliable answer that can benefit to patients and your fellow doctors. Add reference to the answer in this format. Ref: Ref Name.\n",
        "        Here is the context {context}\"\"\"),\n",
        "        HumanMessage(content=question)\n",
        "    ]\n",
        "\n",
        "    # Execute the chat session and get the response\n",
        "    response = chat(messages)\n",
        "\n",
        "        # Wrap the response text for better readability\n",
        "    #wrapped_text = textwrap.fill(response.content, width=80)  # Adjust 'width' as needed\n",
        "\n",
        "    #return wrapped_text\n",
        "    return response.content\n",
        "    # Assuming the response object structure allows direct access to the answer, otherwise adjust accordingly\n",
        "\n",
        "\n",
        "@bot.message_handler(commands=['start', 'help'])\n",
        "def send_welcome(message):\n",
        "    bot.send_message(message.chat.id, \"Welcome! Send me your query and I'll try to find an answer.\")\n",
        "\n",
        "@bot.message_handler(func=lambda message: True)\n",
        "def handle_query(message):\n",
        "    # Your logic to handle the query and search documents\n",
        "    question = message.text\n",
        "    docs = db.similarity_search(question,k=2) # Assuming 'similarity_search' returns a list of matching documents\n",
        "    print(docs)\n",
        "\n",
        "    if docs:\n",
        "        matched_chunk = docs[0]  # Assuming the first document is the most relevant\n",
        "        print(matched_chunk.page_content)\n",
        "        \n",
        "\n",
        "        answer = ask_question(str(question),str(matched_chunk))  # Process the document to generate an answer\n",
        "        response_message = f\"{answer}\"\n",
        "    else:\n",
        "        response_message = \"Sorry, I couldn't find relevant information.\"\n",
        "\n",
        "    bot.send_message(message.chat.id, response_message)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    bot.infinity_polling(interval=0, timeout=20)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
